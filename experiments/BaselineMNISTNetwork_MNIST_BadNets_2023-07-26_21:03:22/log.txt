Total train samples: 60000
Total test samples: 10000
Batch size: 128
iteration every epoch: 468
Initial learning rate: 0.1
[2023-07-26_21:03:24] Epoch:1/200, iteration:100/468, lr: 0.1, loss: 0.43051648139953613, time: 1.2481968402862549
[2023-07-26_21:03:24] Epoch:1/200, iteration:200/468, lr: 0.1, loss: 0.31081900000572205, time: 0.548487663269043
[2023-07-26_21:03:25] Epoch:1/200, iteration:300/468, lr: 0.1, loss: 0.29823940992355347, time: 0.5907812118530273
[2023-07-26_21:03:25] Epoch:1/200, iteration:400/468, lr: 0.1, loss: 0.20784862339496613, time: 0.5594701766967773
[2023-07-26_21:03:26] Epoch:2/200, iteration:31/468, lr: 0.1, loss: 0.02696564793586731, time: 0.8122215270996094
[2023-07-26_21:03:27] Epoch:2/200, iteration:131/468, lr: 0.1, loss: 0.0551961250603199, time: 0.6066725254058838
[2023-07-26_21:03:27] Epoch:2/200, iteration:231/468, lr: 0.1, loss: 0.07440127432346344, time: 0.5477583408355713
[2023-07-26_21:03:28] Epoch:2/200, iteration:331/468, lr: 0.1, loss: 0.03588956966996193, time: 0.5402841567993164
[2023-07-26_21:03:28] Epoch:2/200, iteration:431/468, lr: 0.1, loss: 0.025284340605139732, time: 0.529632568359375
[2023-07-26_21:03:29] Epoch:3/200, iteration:62/468, lr: 0.1, loss: 0.04993590712547302, time: 0.7925510406494141
[2023-07-26_21:03:30] Epoch:3/200, iteration:162/468, lr: 0.1, loss: 0.006586258765310049, time: 0.5271718502044678
[2023-07-26_21:03:30] Epoch:3/200, iteration:262/468, lr: 0.1, loss: 0.013602550141513348, time: 0.5970175266265869
